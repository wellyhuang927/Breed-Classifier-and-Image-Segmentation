# Breed-Classifier-and-Image-Segmentation

This project successfully leverages the Oxford-IIIT Pet Dataset to tackle the challenges of breed classification and segmentation. By employing transfer learning techniques, the models achieved state-of-the-art performance in both tasks. The EfficientNetV2-S model excelled in breed classification, delivering outstanding accuracy, while the MobileNetV2 model provided highly accurate segmentation results. This work demonstrates the effectiveness of modern deep learning architectures in handling complex computer vision tasks related to animal images.

## Table of Contents

- [Overview](#overview)
- [Usage](#usage)
- [Dataset](#dataset)
- [Model Architecture](#model-architecture)
- [Training](#training)
- [Evaluation](#evaluation)
- [Results](#results)
- [Visualization](#visualization)
- [Contributing](#contributing)
- [License](#license)
- [Contact](#contact)

## Overview

### Problem Statement
In the field of computer vision, accurately classifying and segmenting images is crucial for various applications, ranging from autonomous vehicles to medical imaging. However, these tasks become significantly more challenging when dealing with fine-grained details, such as distinguishing between similar breeds of animals or precisely segmenting objects with complex boundaries. This project addresses these challenges by developing robust models for both breed classification and image segmentation of pet (dogs and cats) images.

### Key Features
- **Dual-Task Modeling**: The project tackles both classification and segmentation, offering a comprehensive solution for analyzing pet images.
- **Transfer Learning**: Leveraging pre-trained models allows for rapid convergence and high accuracy with relatively small datasets.
- **User-Friendly Interface with Streamlit**: The application features an intuitive Streamlit interface that allows users to upload a picture and instantly receive both classification and segmentation results. This streamlined approach makes it easy for users to interact with the model and obtain detailed insights without needing any technical expertise.

## Usage

Refer to the online application: https://breed-classifier-and-image-segmentation.streamlit.app/

The initial screen presented upon opening the application is as follows:
![image](https://github.com/user-attachments/assets/2d89f858-7c08-4449-a30f-b50371aff793)

After an image is uploaded by the user, the resulting screen will appear as follows:
![image](https://github.com/user-attachments/assets/4a8f98b3-59fb-4ae2-ae03-075a2010d4ae)

The results are displayed in three main sections:
- **Image Metadata:**
    - **File Name:** The name of the uploaded image file.
    - **File Size:** The size of the image file, typically in bytes or megabytes.
    - **Dimensions:** The width and height of the image, specified in pixels.
- **Classification:**
    - **Predicted Class Index:** The index number assigned to the predicted class according to the model's classification scheme.
    - **Predicted Class Type (Dog / Cat):** The general category or type that the image is classified into.
    - **Predicted Class Label:** The specific breed of the predicted class.
    - **Prediction Probabilities:** The confidence scores for each possible class, showing the likelihood of the image belonging to each class.
- **Segmentation:**
    - **Original Image:** The unmodified image as uploaded by the user.
    - **Prediction Mask:** The segmentation mask generated by the model, highlighting the segmented areas in the image, with .
        - **Black** represents the animal.
        - **White** denotes the border around the animal.
        - **Gray** indicates the background.

## Dataset

Details about the dataset(s) used:
- Dataset name(s) and source(s)
- Preprocessing steps
- Train/Validation/Test split
- Any custom data augmentation applied

## Model Architecture

Describe the model architecture(s) used:
- **Classification Model:**
  - Layers, activation functions, etc.
- **Segmentation Model:**
  - Encoder-decoder structure, U-Net, etc.

Include model diagrams or code snippets if relevant.

## Training

Instructions for training the models:

- Details about the training process:
  - Loss functions, optimizers, learning rate schedules
  - Hyperparameters and their values
  - Any transfer learning techniques used

## Evaluation

Explain how to evaluate the trained models:
- **Classification:**
  - Metrics (accuracy, F1-score, etc.)
- **Segmentation:**
  - Metrics (IoU, Dice coefficient, etc.)
  
Include example commands and expected outputs.

## Results

Summarize the results achieved by your models:
- Performance metrics
- Comparison with other methods
- Examples of predictions (images with ground truth and model output)

Include tables, charts, and visualizations if applicable.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Contact

Provide your contact information:
- Welly Huang
- weichung.huang927@gmail.com
- [LinkedIn](https://www.linkedin.com/in/weichunghuang0927/)
- [GitHub](https://github.com/wellyhuang927)
